{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUfWhBFyohFOTwiquNjt8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorDiamandi/base_ML_Project/blob/BestResult/Colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMjKdkHdlpDo",
        "outputId": "e592e696-f008-47d0-a2b7-662815944f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5\n",
            "From (redirected): https://drive.google.com/uc?id=1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5&confirm=t&uuid=ee4530b2-1a7a-4756-b980-54cff6c44b49\n",
            "To: /content/train.csv\n",
            "100%|██████████| 116M/116M [00:01<00:00, 59.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded as: train.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1j7x8xhMimKbvW62D-XeDfuRyj9ia636q\n",
            "To: /content/valid.csv\n",
            "100%|██████████| 3.32M/3.32M [00:00<00:00, 34.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded as: valid.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pathlib import Path\n",
        "\n",
        "def download_from_gdrive(url, filename):\n",
        "    # Extract the file ID from the URL\n",
        "    file_id = url.split('/')[-2]\n",
        "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "    # Download the file\n",
        "    if Path(filename).exists():\n",
        "        print(f\"File '{filename}' already exists. Skipping download.\")\n",
        "    else:\n",
        "        gdown.download(download_url, filename, quiet=False)\n",
        "        print(f\"File downloaded as: {filename}\")\n",
        "\n",
        "train = 'https://drive.google.com/file/d/1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5/view?usp=drive_link'\n",
        "valid = 'https://drive.google.com/file/d/1j7x8xhMimKbvW62D-XeDfuRyj9ia636q/view?usp=drive_link'\n",
        "# Example usage\n",
        "\n",
        "download_from_gdrive(train, 'train.csv')\n",
        "download_from_gdrive(valid, 'valid.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model functions\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "def train_and_evaluate_model(X_train, X_test, y_train, y_test, tree_depth, level_of_parallelism, number_of_trees,\n",
        "                             max_features):\n",
        "    for depth in tree_depth:\n",
        "        model = RandomForestRegressor(\n",
        "                random_state=100,\n",
        "                n_jobs=level_of_parallelism,\n",
        "                n_estimators=number_of_trees,\n",
        "                max_depth=depth,\n",
        "                max_features=max_features)\n",
        "\n",
        "\n",
        "        print('Fitting the model...')\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        print('Testing the model...')\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        rmse_test = get_rmse(y_test, y_test_pred)\n",
        "        rmse_train = get_rmse(y_train, y_train_pred)\n",
        "\n",
        "        print(f'Tree depth - {depth}')\n",
        "        print(f'STD Test - {y_test.std()}')\n",
        "        print(f'STD Train - {y_train.std()}')\n",
        "        print(f'RMSE Test - {rmse_test}')\n",
        "        print(f'RMSE Train - {rmse_train}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kOhM8hbAZ2Ko"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data functions\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Function to retrieve statistic parameters from numerical columns of the train dataframe\n",
        "def compute_statistics(df):\n",
        "    numeric_df = df.select_dtypes(include='number')\n",
        "\n",
        "    mean_values = numeric_df.mean()\n",
        "    iqr_values = numeric_df.quantile(0.75) - numeric_df.quantile(0.25)\n",
        "    zscore_values = (numeric_df.mean() / numeric_df.std()).mean()\n",
        "\n",
        "    # Mean without extremes (assuming extremes are values outside 1.5*IQR)\n",
        "    def mean_without_extremes(series):\n",
        "        Q1 = series.quantile(0.25)\n",
        "        Q3 = series.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        filtered_series = series[(series >= Q1 - 1.5 * IQR) & (series <= Q3 + 1.5 * IQR)]\n",
        "        return filtered_series.mean()\n",
        "\n",
        "    mean_no_extremes_values = numeric_df.apply(mean_without_extremes)\n",
        "\n",
        "    statistics_df = pd.DataFrame({\n",
        "        'mean': mean_values,\n",
        "        'iqr': iqr_values,\n",
        "        'zscore': [zscore_values] * len(numeric_df.columns),\n",
        "        'mean_without_extremes': mean_no_extremes_values\n",
        "    })\n",
        "\n",
        "    statistics_df = statistics_df.T\n",
        "    return statistics_df\n",
        "\n",
        "\n",
        "def get_stat_value(method, column, statistics_df):\n",
        "  if method not in statistics_df.index:\n",
        "    raise ValueError(f\"Method {method} not found in statistics DataFrame\")\n",
        "  return statistics_df.loc[method, column]\n",
        "\n",
        "\n",
        "def replace_outliers(df, column, method, statistics_df):\n",
        "    stat_value = get_stat_value(method, column, statistics_df)\n",
        "\n",
        "    # Define the threshold for identifying outliers\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Replace outliers with the statistical method value\n",
        "    df[column] = df[column].apply(lambda x: stat_value if x < lower_bound or x > upper_bound else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def replace_nans(df, column, method, statistics_df):\n",
        "    stat_value = get_stat_value(method, column, statistics_df)\n",
        "    df[column] = df[column].fillna(stat_value)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_rmse(y, y_pred):\n",
        "    return mean_squared_error(y, y_pred) ** 0.5\n",
        "\n",
        "\n",
        "def split_product_class_series(series):\n",
        "    equipment_type = []\n",
        "    details = []\n",
        "\n",
        "    for item in series:\n",
        "        if pd.isna(item):\n",
        "            equipment_type.append(None)\n",
        "            details.append(None)\n",
        "        else:\n",
        "            split_item = item.split(' - ', 1)\n",
        "            equipment_type.append(split_item[0])\n",
        "            details.append(split_item[1] if len(split_item) > 1 else None)\n",
        "\n",
        "    return pd.Series(equipment_type), pd.Series(details)"
      ],
      "metadata": {
        "id": "ju1gMoUpbq2b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df_valid = pd.read_csv('valid.csv')"
      ],
      "metadata": {
        "id": "KE2pPmGchFHY",
        "outputId": "f9eedb3f-a4a1-4b2d-f718-a692de58ad19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6adbd7aebcbe>:1: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('train.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get df columns datatypes\n",
        "\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "TXGw8hntWGlm",
        "outputId": "807fe612-d45d-411b-b801-05fe18e4489a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalesID                       int64\n",
              "SalePrice                     int64\n",
              "MachineID                     int64\n",
              "ModelID                       int64\n",
              "datasource                    int64\n",
              "auctioneerID                float64\n",
              "YearMade                      int64\n",
              "MachineHoursCurrentMeter    float64\n",
              "UsageBand                    object\n",
              "saledate                     object\n",
              "fiModelDesc                  object\n",
              "fiBaseModel                  object\n",
              "fiSecondaryDesc              object\n",
              "fiModelSeries                object\n",
              "fiModelDescriptor            object\n",
              "ProductSize                  object\n",
              "fiProductClassDesc           object\n",
              "state                        object\n",
              "ProductGroup                 object\n",
              "ProductGroupDesc             object\n",
              "Drive_System                 object\n",
              "Enclosure                    object\n",
              "Forks                        object\n",
              "Pad_Type                     object\n",
              "Ride_Control                 object\n",
              "Stick                        object\n",
              "Transmission                 object\n",
              "Turbocharged                 object\n",
              "Blade_Extension              object\n",
              "Blade_Width                  object\n",
              "Enclosure_Type               object\n",
              "Engine_Horsepower            object\n",
              "Hydraulics                   object\n",
              "Pushblock                    object\n",
              "Ripper                       object\n",
              "Scarifier                    object\n",
              "Tip_Control                  object\n",
              "Tire_Size                    object\n",
              "Coupler                      object\n",
              "Coupler_System               object\n",
              "Grouser_Tracks               object\n",
              "Hydraulics_Flow              object\n",
              "Track_Type                   object\n",
              "Undercarriage_Pad_Width      object\n",
              "Stick_Length                 object\n",
              "Thumb                        object\n",
              "Pattern_Changer              object\n",
              "Grouser_Type                 object\n",
              "Backhoe_Mounting             object\n",
              "Blade_Type                   object\n",
              "Travel_Controls              object\n",
              "Differential_Type            object\n",
              "Steering_Controls            object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop bad columns\n",
        "\n",
        "df.drop(['MachineHoursLeft'], axis=1, inplace=True)\n",
        "df_valid.drop(['MachineHoursLeft'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "XYPGRHLuWWl8",
        "outputId": "76811ba8-ea60-446d-95c2-ffd689ed6ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['UsageBand', 'saledate', 'fiModelDesc', 'fiBaseModel',\n",
              "       'fiSecondaryDesc', 'fiModelSeries', 'fiModelDescriptor', 'ProductSize',\n",
              "       'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc',\n",
              "       'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control',\n",
              "       'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension',\n",
              "       'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics',\n",
              "       'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size',\n",
              "       'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow',\n",
              "       'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb',\n",
              "       'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type',\n",
              "       'Travel_Controls', 'Differential_Type', 'Steering_Controls'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "source": [
        "# convert 'YearMade' column to 'Age'\n",
        "\n",
        "df['Age'] = 2024 - df['YearMade']\n",
        "df['AgeAtLastSale'] = (pd.to_datetime(df['saledate']) - pd.to_datetime(df['YearMade'].clip(lower=1900), format='%Y')).dt.days\n",
        "df.drop('YearMade', axis=1, inplace=True)\n",
        "\n",
        "df_valid['Age'] = 2024 - df_valid['YearMade']\n",
        "df_valid['AgeAtLastSale'] = (pd.to_datetime(df_valid['saledate']) - pd.to_datetime(df_valid['YearMade'].clip(lower=1900), format='%Y')).dt.days\n",
        "df_valid.drop('YearMade', axis=1, inplace=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WguzR0M5JCN2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split 'fiProductDesc' column\n",
        "\n",
        "df['ProductClassName'],df['ProductClassCharacteristic'] = split_product_class_series(df['fiProductClassDesc'])\n",
        "df_valid['ProductClassName'],df_valid['ProductClassCharacteristic'] = split_product_class_series(df_valid['fiProductClassDesc'])"
      ],
      "metadata": {
        "id": "egV2666vdubL"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 'MachineID' column into 'TimesAppearing' column\n",
        "\n",
        "df['TimesAppearing'] = df['MachineID'].map(df['MachineID'].value_counts())\n",
        "df.drop('MachineID', axis=1, inplace=True)\n",
        "\n",
        "df_valid['TimesAppearing'] = df_valid['MachineID'].map(df_valid['MachineID'].value_counts())\n",
        "df_valid.drop('MachineID', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "5mGwN3CfX7o2"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicated columns: 'ProductGroupDesc'\n",
        "\n",
        "df.drop(['ProductGroupDesc','ProductClassName'], axis=1, inplace=True)\n",
        "df_valid.drop(['ProductGroupDesc','ProductClassName'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "UmE4U4i3YbOR"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "source": [
        "# replace NaN with -1 in 'ID' columns\n",
        "\n",
        "df[['datasource', 'auctioneerID']] = df[['datasource', 'auctioneerID']].fillna(-1)\n",
        "df_valid[['datasource', 'auctioneerID']] = df_valid[['datasource', 'auctioneerID']].fillna(-1)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BvVsi9wVFQl5"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split train and test data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(columns=['SalePrice']), df['SalePrice'], test_size=0.3, random_state=100)"
      ],
      "metadata": {
        "id": "aAwx1KGiCa4D"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get statistics dataframe using compute_statistics function from the X_train\n",
        "statistics_df = compute_statistics(X_train)"
      ],
      "metadata": {
        "id": "p0oIPYMgC3qG"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Use replace_outliers function in order to replace outliers\n",
        "in the 'MachineHoursCurrentMeter' column using statistics_df and IQR method \"\"\"\n",
        "\n",
        "X_train = replace_outliers(X_train, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "X_test = replace_outliers(X_test, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "df_valid = replace_outliers(df_valid, 'MachineHoursCurrentMeter', 'iqr', statistics_df)"
      ],
      "metadata": {
        "id": "v9J6yjErhWlq"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Use replace_outliers function in order to replace outliers\n",
        "in the 'Age' column using statistics_df and mean method \"\"\"\n",
        "\n",
        "X_train = replace_outliers(X_train, 'Age', 'mean_without_extremes', statistics_df)\n",
        "X_test = replace_outliers(X_test, 'Age', 'mean_without_extremes', statistics_df)\n",
        "df_valid = replace_outliers(df_valid, 'Age', 'mean_without_extremes', statistics_df)"
      ],
      "metadata": {
        "id": "q6y9pX3XJ9ED"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Use replace_nans function in order to replace NaN values\n",
        "in the 'MachineHoursCurrentMeter' column using statistics_df and IQR method \"\"\"\n",
        "\n",
        "X_train = replace_nans(X_train, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "X_test = replace_nans(X_test, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "df_valid = replace_nans(df_valid, 'MachineHoursCurrentMeter', 'iqr', statistics_df)"
      ],
      "metadata": {
        "id": "CdAC3mv0LNxU"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace NaN with 'Missing' in textual columns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':\n",
        "        if X_train[col].apply(type).nunique() > 1:\n",
        "            X_train[col] = X_train[col].fillna('Missing').astype(str)\n",
        "        X_train[col] = le.fit_transform(X_train[col])\n",
        "\n",
        "for col in X_test.columns:\n",
        "    if X_test[col].dtype == 'object':\n",
        "        if X_test[col].apply(type).nunique() > 1:\n",
        "            X_test[col] = X_test[col].fillna('Missing').astype(str)\n",
        "        X_test[col] = le.fit_transform(X_test[col])\n",
        "\n",
        "\n",
        "for col in df_valid.columns:\n",
        "    if df_valid[col].dtype == 'object':\n",
        "        if df_valid[col].apply(type).nunique() > 1:\n",
        "            df_valid[col] = df_valid[col].fillna('Missing').astype(str)\n",
        "        df_valid[col] = le.fit_transform(df_valid[col])\n",
        "\n"
      ],
      "metadata": {
        "id": "diV5Pq4UYqID"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert categorical values to lables in all 3 dataframes\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Create the column transformer with OneHotEncoder\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit the preprocessor on X_train and transform all dataframes\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "X_valid_transformed = preprocessor.transform(df_valid)\n",
        "\n",
        "# Convert transformed arrays back to dataframes with proper column names\n",
        "X_train_transformed = pd.DataFrame(X_train_transformed, columns=preprocessor.get_feature_names_out())\n",
        "X_test_transformed = pd.DataFrame(X_test_transformed, columns=preprocessor.get_feature_names_out())\n",
        "X_valid_transformed = pd.DataFrame(X_valid_transformed, columns=preprocessor.get_feature_names_out())"
      ],
      "metadata": {
        "id": "EkpKPP10PZpO"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model = train_and_evaluate_model(X_train_transformed, X_test_transformed, y_train, y_test, [16],\n",
        "                                 -1, 20, 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4JPXcR2TBj9",
        "outputId": "6abaf807-17f5-46d2-8703-25aff11892d5"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the model...\n",
            "Testing the model...\n",
            "Tree depth - 16\n",
            "STD Test - 22995.709788960918\n",
            "STD Train - 23054.44179044156\n",
            "RMSE Test - 11573.133611443149\n",
            "RMSE Train - 6057.5839482426145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Model\n",
        "y_valid_pred = model.predict(X_valid_transformed)"
      ],
      "metadata": {
        "id": "79BH6lGfUCYr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the prediction DataFrame with only 'SalesID' and 'Predicted_SalePrice'\n",
        "df_predictions = pd.DataFrame({\n",
        "    'SalesID': X_valid_transformed['SalesID'],\n",
        "    'SalePrice': y_valid_pred\n",
        "})\n",
        "df_predictions.to_csv('valid_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "NGk-DT4zjXkb"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('valid_predictions.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TKkPGrIJpNCf",
        "outputId": "fdf8d367-3d9c-4502-8e50-cd695fe8ccaf"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2787cb65-488d-41d2-ae26-8a747b07e58d\", \"valid_predictions.csv\", 305240)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print features importance order it descending\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "importance_list = [(importance, feature) for feature, importance in zip(feature_names, feature_importances)]\n",
        "importance_list.sort(reverse=True)\n",
        "\n",
        "for importance, feature in importance_list:\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gstA97Hb3D_",
        "outputId": "db385713-2186-4d2a-f207-f7ea0ed5ae4a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgeAtLastSale: 0.19799973933897025\n",
            "ProductSize: 0.18456433912211362\n",
            "Age: 0.10021552339870568\n",
            "fiBaseModel: 0.06665314620390204\n",
            "ModelID: 0.062032727261508006\n",
            "Enclosure: 0.05932902460296898\n",
            "fiProductClassDesc: 0.049593214926255\n",
            "fiModelDesc: 0.04231276728386864\n",
            "fiSecondaryDesc: 0.03463507852907022\n",
            "Coupler_System: 0.03062715674315703\n",
            "ProductClassCharacteristic: 0.030154666622460115\n",
            "SalesID: 0.01767546463973773\n",
            "fiModelDescriptor: 0.01579055099517206\n",
            "Grouser_Tracks: 0.010833819732083156\n",
            "Tire_Size: 0.009275402600574701\n",
            "ProductGroup: 0.00842372027153318\n",
            "Enclosure_Type: 0.0074547381414718904\n",
            "saledate: 0.005834653788172878\n",
            "Hydraulics_Flow: 0.005596966099010357\n",
            "state: 0.004700372195093061\n",
            "Blade_Width: 0.0046516516541280925\n",
            "Ripper: 0.004318177286488369\n",
            "fiModelSeries: 0.004231965967083417\n",
            "Pushblock: 0.004176817442604224\n",
            "Hydraulics: 0.003863466317511056\n",
            "Tip_Control: 0.0031296014216171996\n",
            "auctioneerID: 0.002851691830721068\n",
            "MachineHoursCurrentMeter: 0.0022348654203995\n",
            "Engine_Horsepower: 0.002180121649207222\n",
            "Travel_Controls: 0.0021197319110980678\n",
            "Blade_Extension: 0.0020350067705437475\n",
            "Scarifier: 0.0016214224857216612\n",
            "Track_Type: 0.0015846162196613066\n",
            "Drive_System: 0.0015767138776006024\n",
            "Blade_Type: 0.0015136710884911249\n",
            "Ride_Control: 0.001484082579060028\n",
            "TimesAppearing: 0.0012724175858178709\n",
            "datasource: 0.0012699195923217305\n",
            "Undercarriage_Pad_Width: 0.0011684973912589815\n",
            "Stick_Length: 0.0011176277690421415\n",
            "UsageBand: 0.0010545584801227852\n",
            "Coupler: 0.0009548192399337609\n",
            "Transmission: 0.0009384413292148474\n",
            "Grouser_Type: 0.0008204651558226427\n",
            "Pattern_Changer: 0.0007417442234557576\n",
            "Forks: 0.0007260477201462021\n",
            "Pad_Type: 0.0006964452986786723\n",
            "Thumb: 0.0004898449974511266\n",
            "Differential_Type: 0.0003846985113752833\n",
            "Backhoe_Mounting: 0.0003797184640638157\n",
            "Steering_Controls: 0.0002555412559460477\n",
            "Stick: 0.0002360923320143842\n",
            "Turbocharged: 0.00021644423556873224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTKkQB14ia8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}