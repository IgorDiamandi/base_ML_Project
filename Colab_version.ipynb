{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJrMIZQ5akJ/Tpg5/3yARZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorDiamandi/base_ML_Project/blob/BestResult/Colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMjKdkHdlpDo",
        "outputId": "6fbee831-7337-4fbc-bcbe-8f1c89d9e2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'train.csv' already exists. Skipping download.\n",
            "File 'valid.csv' already exists. Skipping download.\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pathlib import Path\n",
        "\n",
        "def download_from_gdrive(url, filename):\n",
        "    # Extract the file ID from the URL\n",
        "    file_id = url.split('/')[-2]\n",
        "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "    # Download the file\n",
        "    if Path(filename).exists():\n",
        "        print(f\"File '{filename}' already exists. Skipping download.\")\n",
        "    else:\n",
        "        gdown.download(download_url, filename, quiet=False)\n",
        "        print(f\"File downloaded as: {filename}\")\n",
        "\n",
        "train = 'https://drive.google.com/file/d/1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5/view?usp=drive_link'\n",
        "valid = 'https://drive.google.com/file/d/1j7x8xhMimKbvW62D-XeDfuRyj9ia636q/view?usp=drive_link'\n",
        "# Example usage\n",
        "\n",
        "download_from_gdrive(train, 'train.csv')\n",
        "download_from_gdrive(valid, 'valid.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model functions\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "def train_and_evaluate_model(X_train, X_test, y_train, y_test, tree_depth, level_of_parallelism, number_of_trees,\n",
        "                             max_features):\n",
        "    for depth in tree_depth:\n",
        "        model = RandomForestRegressor(\n",
        "                random_state=100,\n",
        "                n_jobs=level_of_parallelism,\n",
        "                n_estimators=number_of_trees,\n",
        "                max_depth=depth,\n",
        "                max_features=max_features)\n",
        "\n",
        "\n",
        "        print('Fitting the model...')\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        print('Testing the model...')\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        rmse_test = get_rmse(y_test, y_test_pred)\n",
        "        rmse_train = get_rmse(y_train, y_train_pred)\n",
        "\n",
        "        print(f'Tree depth - {depth}')\n",
        "        print(f'STD Test - {y_test.std()}')\n",
        "        print(f'STD Train - {y_train.std()}')\n",
        "        print(f'RMSE Test - {rmse_test}')\n",
        "        print(f'RMSE Train - {rmse_train}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kOhM8hbAZ2Ko"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data functions\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Function to retrieve statistic parameters from numerical columns of the train dataframe\n",
        "def compute_statistics(df):\n",
        "    numeric_df = df.select_dtypes(include='number')\n",
        "\n",
        "    mean_values = numeric_df.mean()\n",
        "    iqr_values = numeric_df.quantile(0.75) - numeric_df.quantile(0.25)\n",
        "    zscore_values = (numeric_df.mean() / numeric_df.std()).mean()\n",
        "\n",
        "    # Mean without extremes (assuming extremes are values outside 1.5*IQR)\n",
        "    def mean_without_extremes(series):\n",
        "        Q1 = series.quantile(0.25)\n",
        "        Q3 = series.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        filtered_series = series[(series >= Q1 - 1.5 * IQR) & (series <= Q3 + 1.5 * IQR)]\n",
        "        return filtered_series.mean()\n",
        "\n",
        "    mean_no_extremes_values = numeric_df.apply(mean_without_extremes)\n",
        "\n",
        "    statistics_df = pd.DataFrame({\n",
        "        'mean': mean_values,\n",
        "        'iqr': iqr_values,\n",
        "        'zscore': [zscore_values] * len(numeric_df.columns),\n",
        "        'mean_without_extremes': mean_no_extremes_values\n",
        "    })\n",
        "\n",
        "    statistics_df = statistics_df.T\n",
        "    return statistics_df\n",
        "\n",
        "\n",
        "def get_stat_value(method, column, statistics_df):\n",
        "  if method not in statistics_df.index:\n",
        "    raise ValueError(f\"Method {method} not found in statistics DataFrame\")\n",
        "  return statistics_df.loc[method, column]\n",
        "\n",
        "\n",
        "def replace_outliers(df, column, method, statistics_df):\n",
        "    stat_value = get_stat_value(method, column, statistics_df)\n",
        "\n",
        "    # Define the threshold for identifying outliers\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Replace outliers with the statistical method value\n",
        "    df[column] = df[column].apply(lambda x: stat_value if x < lower_bound or x > upper_bound else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def replace_nans(df, column, method, statistics_df):\n",
        "    stat_value = get_stat_value(method, column, statistics_df)\n",
        "    df[column] = df[column].fillna(stat_value)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_rmse(y, y_pred):\n",
        "    return mean_squared_error(y, y_pred) ** 0.5\n",
        "\n",
        "\n",
        "def split_product_class_series(series):\n",
        "    equipment_type = []\n",
        "    details = []\n",
        "\n",
        "    for item in series:\n",
        "        if pd.isna(item):\n",
        "            equipment_type.append(None)\n",
        "            details.append(None)\n",
        "        else:\n",
        "            split_item = item.split(' - ', 1)\n",
        "            equipment_type.append(split_item[0])\n",
        "            details.append(split_item[1] if len(split_item) > 1 else None)\n",
        "\n",
        "    return pd.Series(equipment_type), pd.Series(details)"
      ],
      "metadata": {
        "id": "ju1gMoUpbq2b"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df_valid = pd.read_csv('valid.csv')"
      ],
      "metadata": {
        "id": "KE2pPmGchFHY",
        "outputId": "9c601690-a35e-46a5-c292-399258b2c6d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-136-6adbd7aebcbe>:1: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('train.csv')\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# convert 'YearMade' column to 'Age'\n",
        "\n",
        "df['Age'] = 2024 - df['YearMade']\n",
        "# Clamp 'YearMade' to a reasonable minimum before converting to datetime\n",
        "#df['AgeAtLastSale'] = pd.to_datetime(df['saledate']) - pd.to_datetime(df['YearMade'].clip(lower=1900), format='%Y')\n",
        "df.drop('YearMade', axis=1, inplace=True)\n",
        "\n",
        "df_valid['Age'] = 2024 - df_valid['YearMade']\n",
        "# Clamp 'YearMade' to a reasonable minimum before converting to datetime, and convert 'saledate' to datetime\n",
        "#df_valid['AgeAtLastSale'] = pd.to_datetime(df_valid['saledate']) - pd.to_datetime(df_valid['YearMade'].clip(lower=1900), format='%Y')\n",
        "df_valid.drop('YearMade', axis=1, inplace=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WguzR0M5JCN2"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split 'fiProductDesc' column\n",
        "\n",
        "df['ProductClassName'],df['ProductClassCharacteristic'] = split_product_class_series(df['fiProductClassDesc'])\n",
        "df_valid['ProductClassName'],df_valid['ProductClassCharacteristic'] = split_product_class_series(df_valid['fiProductClassDesc'])"
      ],
      "metadata": {
        "id": "egV2666vdubL"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 'MachineID' column into 'TimesAppearing' column\n",
        "\n",
        "df['TimesAppearing'] = df['MachineID'].map(df['MachineID'].value_counts())\n",
        "df.drop('MachineID', axis=1, inplace=True)\n",
        "\n",
        "df_valid['TimesAppearing'] = df_valid['MachineID'].map(df_valid['MachineID'].value_counts())\n",
        "df_valid.drop('MachineID', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "5mGwN3CfX7o2"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicated columns: 'ProductGroupDesc'\n",
        "\n",
        "df.drop(['ProductGroupDesc','ProductClassName'], axis=1, inplace=True)\n",
        "df_valid.drop(['ProductGroupDesc','ProductClassName'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "UmE4U4i3YbOR"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace NaN values with 'missing' for non-numeric fields\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col].fillna('missing', inplace=True)\n",
        "\n",
        "\n",
        "for col in df_valid.columns:\n",
        "    if df_valid[col].dtype == 'object':\n",
        "        df_valid[col].fillna('missing', inplace=True)"
      ],
      "metadata": {
        "id": "1_pZv78LZK8t"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wdjNvPLoFZ-Y"
      }
    },
    {
      "source": [
        "# replace NaN with -1 in 'ID' columns\n",
        "\n",
        "df[['datasource', 'auctioneerID']] = df[['datasource', 'auctioneerID']].fillna(-1)\n",
        "df_valid[['datasource', 'auctioneerID']] = df_valid[['datasource', 'auctioneerID']].fillna(-1)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BvVsi9wVFQl5"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split train and test data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(columns=['SalePrice']), df['SalePrice'], test_size=0.3, random_state=100)"
      ],
      "metadata": {
        "id": "aAwx1KGiCa4D"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get statistics dataframe using compute_statistics function from the X_train\n",
        "statistics_df = compute_statistics(X_train)"
      ],
      "metadata": {
        "id": "p0oIPYMgC3qG"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Use replace_outliers function in order to replace outliers\n",
        "in the 'MachineHoursCurrentMeter' column using statistics_df and IQR method \"\"\"\n",
        "\n",
        "X_train = replace_outliers(X_train, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "X_test = replace_outliers(X_test, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "df_valid = replace_outliers(df_valid, 'MachineHoursCurrentMeter', 'iqr', statistics_df)"
      ],
      "metadata": {
        "id": "v9J6yjErhWlq"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Use replace_outliers function in order to replace outliers\n",
        "in the 'Age' column using statistics_df and mean method \"\"\"\n",
        "\n",
        "X_train = replace_outliers(X_train, 'Age', 'mean', statistics_df)\n",
        "X_test = replace_outliers(X_test, 'Age', 'mean', statistics_df)\n",
        "df_valid = replace_outliers(df_valid, 'Age', 'mean', statistics_df)"
      ],
      "metadata": {
        "id": "q6y9pX3XJ9ED"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Use replace_nans function in order to replace outliers\n",
        "in the 'MachineHoursCurrentMeter' column using statistics_df and IQR method \"\"\"\n",
        "\n",
        "X_train = replace_nans(X_train, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "X_test = replace_nans(X_test, 'MachineHoursCurrentMeter', 'iqr', statistics_df)\n",
        "df_valid = replace_nans(df_valid, 'MachineHoursCurrentMeter', 'iqr', statistics_df)"
      ],
      "metadata": {
        "id": "CdAC3mv0LNxU"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace NaN with 'Missing' in textual columns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':\n",
        "        if X_train[col].apply(type).nunique() > 1:\n",
        "            X_train[col] = X_train[col].fillna('Missing').astype(str)\n",
        "        X_train[col] = le.fit_transform(X_train[col])\n",
        "\n",
        "for col in X_test.columns:\n",
        "    if X_test[col].dtype == 'object':\n",
        "        if X_test[col].apply(type).nunique() > 1:\n",
        "            X_test[col] = X_test[col].fillna('Missing').astype(str)\n",
        "        X_test[col] = le.fit_transform(X_test[col])\n",
        "\n",
        "\n",
        "for col in df_valid.columns:\n",
        "    if df_valid[col].dtype == 'object':\n",
        "        if df_valid[col].apply(type).nunique() > 1:\n",
        "            df_valid[col] = df_valid[col].fillna('Missing').astype(str)\n",
        "        df_valid[col] = le.fit_transform(df_valid[col])\n",
        "\n"
      ],
      "metadata": {
        "id": "diV5Pq4UYqID"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check NaN in X_Train\n",
        "\n",
        "X_train.isna().sum()"
      ],
      "metadata": {
        "id": "l7rdeP_BK7W3",
        "outputId": "8237a21c-4bb3-4b47-c808-ad9a309fed90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalesID                       0\n",
              "ModelID                       0\n",
              "datasource                    0\n",
              "auctioneerID                  0\n",
              "MachineHoursCurrentMeter      0\n",
              "UsageBand                     0\n",
              "saledate                      0\n",
              "fiModelDesc                   0\n",
              "fiBaseModel                   0\n",
              "fiSecondaryDesc               0\n",
              "fiModelSeries                 0\n",
              "fiModelDescriptor             0\n",
              "ProductSize                   0\n",
              "fiProductClassDesc            0\n",
              "state                         0\n",
              "ProductGroup                  0\n",
              "Drive_System                  0\n",
              "Enclosure                     0\n",
              "Forks                         0\n",
              "Pad_Type                      0\n",
              "Ride_Control                  0\n",
              "Stick                         0\n",
              "Transmission                  0\n",
              "Turbocharged                  0\n",
              "Blade_Extension               0\n",
              "Blade_Width                   0\n",
              "Enclosure_Type                0\n",
              "Engine_Horsepower             0\n",
              "Hydraulics                    0\n",
              "Pushblock                     0\n",
              "Ripper                        0\n",
              "Scarifier                     0\n",
              "Tip_Control                   0\n",
              "Tire_Size                     0\n",
              "Coupler                       0\n",
              "Coupler_System                0\n",
              "Grouser_Tracks                0\n",
              "Hydraulics_Flow               0\n",
              "Track_Type                    0\n",
              "Undercarriage_Pad_Width       0\n",
              "Stick_Length                  0\n",
              "Thumb                         0\n",
              "Pattern_Changer               0\n",
              "Grouser_Type                  0\n",
              "Backhoe_Mounting              0\n",
              "Blade_Type                    0\n",
              "Travel_Controls               0\n",
              "Differential_Type             0\n",
              "Steering_Controls             0\n",
              "Age                           0\n",
              "ProductClassCharacteristic    0\n",
              "TimesAppearing                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_and_evaluate_model(X_train, X_test, y_train, y_test, [15], -1, 20,\n",
        "                                 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STyicTQ2aGIx",
        "outputId": "5bb563d5-42f8-4f7d-f76c-3af50fc6cbc1"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the model...\n",
            "Testing the model...\n",
            "Tree depth - 15\n",
            "STD Test - 22995.709788960918\n",
            "STD Train - 23054.44179044156\n",
            "RMSE Test - 12747.583073222002\n",
            "RMSE Train - 8734.391293253819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid = df_valid\n",
        "y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "# Create the prediction DataFrame with only 'SalesID' and 'Predicted_SalePrice'\n",
        "df_predictions = pd.DataFrame({\n",
        "    'SalesID': df_valid['SalesID'],\n",
        "    'SalePrice': y_valid_pred\n",
        "})\n",
        "df_predictions.to_csv('valid_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "NGk-DT4zjXkb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('valid_predictions.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TKkPGrIJpNCf",
        "outputId": "55bc5abd-799e-4862-9cac-0d21401c51c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5664e995-34c5-4a43-b24d-c2d44020bfbc\", \"valid_predictions.csv\", 307813)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print features importance order it descending\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "importance_list = [(importance, feature) for feature, importance in zip(feature_names, feature_importances)]\n",
        "importance_list.sort(reverse=True)\n",
        "\n",
        "for importance, feature in importance_list:\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gstA97Hb3D_",
        "outputId": "804ec6bb-4a7c-425b-ef34-bf495b6ad531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age: 0.19937407506585206\n",
            "ProductSize: 0.10691889839352231\n",
            "SalesID: 0.08207153754382275\n",
            "ModelID: 0.07300923476058667\n",
            "ProductClassCharacteristic: 0.05319805945419628\n",
            "fiSecondaryDesc: 0.05011915152936151\n",
            "fiModelDesc: 0.04547696431017013\n",
            "fiProductClassDesc: 0.04328313362428725\n",
            "fiBaseModel: 0.03834234202871468\n",
            "fiModelDescriptor: 0.03582192624646638\n",
            "saledate: 0.030655716543375417\n",
            "state: 0.020760749250534297\n",
            "ProductGroup: 0.020564596106261848\n",
            "Tire_Size: 0.016754501107996818\n",
            "Enclosure: 0.015835870041758633\n",
            "auctioneerID: 0.015216829140987745\n",
            "MachineHoursCurrentMeter: 0.014636762750531834\n",
            "Drive_System: 0.013355963856597172\n",
            "Pad_Type: 0.012103941017270674\n",
            "Coupler_System: 0.011823749254768676\n",
            "Track_Type: 0.011386670539874175\n",
            "datasource: 0.009893314497543201\n",
            "Ripper: 0.007958961846226305\n",
            "fiModelSeries: 0.007183775188782225\n",
            "Hydraulics: 0.007051763375061887\n",
            "Forks: 0.007007770072411807\n",
            "TimesAppearing: 0.005472211436897077\n",
            "Grouser_Tracks: 0.005382902937514509\n",
            "Ride_Control: 0.005382876577428912\n",
            "Coupler: 0.004056127048041624\n",
            "Transmission: 0.0036322636344376666\n",
            "UsageBand: 0.0033172911644542467\n",
            "Tip_Control: 0.0027230675592378175\n",
            "Thumb: 0.002469143192867553\n",
            "Stick_Length: 0.0023866570175304995\n",
            "Pattern_Changer: 0.0019666347573236097\n",
            "Blade_Type: 0.0018466073462820663\n",
            "Undercarriage_Pad_Width: 0.0018296051037440704\n",
            "Steering_Controls: 0.001772707070315651\n",
            "Travel_Controls: 0.001373393401621054\n",
            "Hydraulics_Flow: 0.0012659624834784181\n",
            "Grouser_Type: 0.0008978150102486539\n",
            "Stick: 0.0007170043777007639\n",
            "Pushblock: 0.0007120221361205474\n",
            "Blade_Width: 0.000607504704538145\n",
            "Turbocharged: 0.000598692162768797\n",
            "Scarifier: 0.0005922335030307752\n",
            "Backhoe_Mounting: 0.00032136034685929256\n",
            "Engine_Horsepower: 0.00029028341062870553\n",
            "Differential_Type: 0.00024277825665680776\n",
            "Blade_Extension: 0.0002264723669610403\n",
            "Enclosure_Type: 0.00011012544634903646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTKkQB14ia8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}